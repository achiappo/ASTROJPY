{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "import pylab as plt\n",
    "from math import log10\n",
    "from emcee import EnsembleSampler\n",
    "\n",
    "from scipy.interpolate import interp1d as interp\n",
    "from scipy.optimize import brentq, minimize_scalar\n",
    "\n",
    "from profiles import build_profile, build_kernel\n",
    "from dispersion import SphericalJeansDispersion\n",
    "from likelihood import GaussianLikelihood\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rh = 0.04\n",
    "D = 39.81\n",
    "theta = 2*rh/D\n",
    "\n",
    "dm = build_profile('NFW')           # NFW profile for DM\n",
    "st = build_profile('plummer',rh=rh) # Plummer Stellar profile\n",
    "kr = build_kernel('iso')            # isotropic kernel\n",
    "dwarf_props = {'D':D, 'theta':theta, 'rt':np.inf, 'with_errs':False}\n",
    "Sigma = SphericalJeansDispersion(dm, st, kr, dwarf_props)\n",
    "\n",
    "directory = '/home/andrea/Desktop/work/DWARF/'\n",
    "R, v = np.loadtxt(directory+'dsphsim/Ret2_data/dsph_001.txt',usecols=(5, 7),unpack=True)\n",
    "vnan = np.isnan(v)\n",
    "v = v[:10]#[~vnan]\n",
    "R = R[:10]#[~vnan]\n",
    "dv = np.zeros_like(v)\n",
    "\n",
    "LL = GaussianLikelihood([R, v, dv, 0.], Sigma)\n",
    "LL.set_free('dm_a')\n",
    "LL.set_free('dm_b')\n",
    "LL.set_free('dm_c')\n",
    "LL.set_free('dm_r0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dm_a', 'dm_b', 'J', 'dm_r0', 'dm_c']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL.free_pars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lnprior(theta, freeJ=False):\n",
    "    if freeJ:\n",
    "        J, r, a, b, c = theta\n",
    "        if 12 < J < 24 and -3 < r < 2 and 0.5 < a < 3 and 2 < b < 6 and 0 < c < 1.2:\n",
    "            return 0.0\n",
    "        return -np.inf\n",
    "    r, a, b, c = theta\n",
    "    if -3 < r < 2 and 0.5 < a < 3 and 2 < b < 6 and 0 < c < 1.2:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def lnlike(theta, args=[], freeJ=False):\n",
    "    if freeJ:\n",
    "        J, r, a, b, c = theta\n",
    "        return -LL(a, b, J, 10**r, c)\n",
    "    J = args\n",
    "    r, a, b, c = theta\n",
    "    return -LL(a, b, J, 10**r, c)\n",
    "\n",
    "def lnprob(theta, args=[], freeJ=False):\n",
    "    if freeJ:\n",
    "        lp = lnprior(theta, freeJ)\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "        return lp + lnlike(theta, args, freeJ)\n",
    "    lp = lnprior(theta, freeJ)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, args, freeJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial scan to locate the minimum $\\mathcal{J}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nthreads = 1\n",
    "initial_dim = len(LL.free_pars)\n",
    "nwalkers = initial_dim*4\n",
    "initial_burnin = 1\n",
    "initial_nsteps = 1\n",
    "initial_p0 = [17, -0.5, 1.5, 4., 0.5]\n",
    "initial_pos0 = [ initial_p0 + \\\n",
    "                np.concatenate( ([2*randn()], 0.1*randn(initial_dim-1)) ) \\\n",
    "                for i in range(nwalkers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multi-threads computation\n",
    "sampler = EnsembleSampler(nwalkers, initial_dim, lnprob, kwargs={'freeJ':True}, threads=nthreads )\n",
    "# Run initial_burnin steps as a burn-in.\n",
    "pos, prob, state = sampler.run_mcmc(initial_pos0, initial_burnin)\n",
    "# Reset the chain to remove the burn-in samples.\n",
    "sampler.reset()\n",
    "# Starting from the final position in the burn-in chain, sample for initial_nsteps.\n",
    "sampler.run_mcmc(pos, initial_nsteps, rstate0=state)\n",
    "# extract samples and likelihood\n",
    "samples = sampler.flatchain\n",
    "lnprobs = sampler.flatlnprobability\n",
    "# find global minimum likelihood value\n",
    "Like_gmin = min( -lnprobs )\n",
    "indLike_gmin = np.where( -lnprobs==Like_gmin )[0][0]\n",
    "# save global minimum likelihood value and corresponding parameters\n",
    "J_gmin = samples[indLike_gmin, 0]\n",
    "params_gmin = samples[indLike_gmin, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## successive scans to build the wings of the profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_burnin = 1\n",
    "new_nsteps = 5\n",
    "new_dim = len(LL.free_pars)-1\n",
    "nwalkers = new_dim*4\n",
    "# initialise sampler with global maximum likelihood parameters\n",
    "new_p0 = params_gmin\n",
    "new_pos0 = [ new_p0 + 0.1*randn(new_dim) for i in range(nwalkers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### left wing of profile likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopL = False\n",
    "nL = 0\n",
    "JL = J_gmin - 0.2\n",
    "LikeL, paramsL, JL_array = [], [], []\n",
    "\n",
    "# build left wing of profile likelihood \n",
    "while not stopL:\n",
    "    nL += 1\n",
    "    new_pos0 = [ new_p0 + 0.1*randn(new_dim) for i in range(nwalkers)]\n",
    "    # instantiate emcee sampler object\n",
    "    sampler = EnsembleSampler(nwalkers, new_dim, lnprob, args=[JL], threads=nthreads)\n",
    "    # Run new_burnin steps as a burn-in.\n",
    "    pos, prob, state = sampler.run_mcmc(new_pos0, new_burnin)\n",
    "    # Reset the chain to remove the burn-in samples.\n",
    "    sampler.reset()\n",
    "    # Starting from the final position in the burn-in chain, sample for new_nsteps.\n",
    "    sampler.run_mcmc(pos, new_nsteps, rstate0=state)\n",
    "    # extract samples and likelihood\n",
    "    samples = sampler.flatchain\n",
    "    lnprobs = sampler.flatlnprobability\n",
    "    # find maximum likelihood value\n",
    "    Like_min = min( -lnprobs )\n",
    "    indLike_min = np.where( -lnprobs==Like_min )[0][0]\n",
    "    # append quantities to their list\n",
    "    JL_array.append( JL )\n",
    "    LikeL.append( Like_min ) # save -logLikelihood value\n",
    "    paramsL.append( samples[indLike_min] )\n",
    "    # check if we reached the 3sigma level\n",
    "    if LikeL[-1] < Like_gmin+4.5:\n",
    "        JL -= 0.2\n",
    "        # set new initial guesses to maximum likelihood parameters just found\n",
    "        new_p0 = samples[indLike_min]\n",
    "    else:\n",
    "        stopL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "J_array = sorted(JL_array, reverse=True)\n",
    "Likes = sorted(LikeL, reverse=True)\n",
    "params = sorted(paramsL, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### right wing of profile likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopR = False\n",
    "nR = 0\n",
    "JR = J_gmin + 0.2\n",
    "LikeR, paramsR, JR_array = [], [], []\n",
    "\n",
    "new_p0 = params_gmin\n",
    "\n",
    "# build left wing of profile likelihood \n",
    "while not stopR:\n",
    "    nR += 1\n",
    "    new_pos0 = [ new_p0 + 0.1*randn(new_dim) for i in range(nwalkers)]\n",
    "    # instantiate emcee sampler object\n",
    "    sampler = EnsembleSampler(nwalkers, new_dim, lnprob, args=[JR], threads=nthreads)\n",
    "    # Run new_burnin steps as a burn-in.\n",
    "    pos, prob, state = sampler.run_mcmc(new_pos0, new_burnin)\n",
    "    # Reset the chain to remove the burn-in samples.\n",
    "    sampler.reset()\n",
    "    # Starting from the final position in the burn-in chain, sample for new_nsteps.\n",
    "    sampler.run_mcmc(pos, new_nsteps, rstate0=state)\n",
    "    # extract samples and likelihood\n",
    "    samples = sampler.flatchain\n",
    "    lnprobs = sampler.flatlnprobability\n",
    "    # find maximum likelihood value\n",
    "    Like_min = min( -lnprobs )\n",
    "    indLike_min = np.where( -lnprobs==Like_min )[0][0]\n",
    "    # append quantities to their list\n",
    "    JR_array.append( JR )\n",
    "    LikeR.append( Like_min ) # save -logLikelihood value\n",
    "    paramsR.append( samples[indLike_min] )\n",
    "    # check if we reached the 3sigma level\n",
    "    if LikeR[-1] < Like_gmin+4.5:\n",
    "        JR += 0.2\n",
    "        # set new initial guesses to maximum likelihood parameters just found\n",
    "        new_p0 = samples[indLike_min]\n",
    "    else:\n",
    "        stopR = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "J_array.append( J_gmin ); J_array.append( JR_array )\n",
    "Likes.append( Like_gmin ); Likes.append( LikeR )\n",
    "params.append( params_gmin ); params.append( paramsR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('results', np.vstack( (J_array, Likes, params) ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
